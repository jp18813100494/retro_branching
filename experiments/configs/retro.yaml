defaults:
  - network: dqn_value_network
  - agent: dqn_agent
  - learner: dqn_learner

environment:
  observation_function: '43_var_features'
  information_function: 'default'
  reward_function: 'retro_binary_fathomed'
  scip_params: 'gasse_2019'

learner:
  path_to_save: '/scratch/datasets/retro_branching'
  agent_reward: 'retro_binary_fathomed'

instances:
  co_class: 'set_covering'
  co_class_kwargs:
    'n_rows': 165
    'n_cols': 230
  #co_class: 'combinatorial_auction'
  #co_class_kwargs:
    #n_items: 10
    #n_bids: 50

experiment:
  seed: 0
  device: 'cuda:0'
  num_epochs: 5000000
  
